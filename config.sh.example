#!/bin/bash
# ML Training Server - Configuration Template
# Copy this file to config.sh and customize for your setup:
#   cp config.sh.example config.sh
#   nano config.sh
#
# After editing, validate with: ./scripts/00-validate-config.sh
#
# NOTE: Storage configuration cannot be changed after running 01-setup-storage.sh
#       without wiping disks! All other settings can be changed and scripts re-run.

#==============================================================================
# SYSTEM CONFIGURATION
#==============================================================================

SERVER_HOSTNAME="ml-train-server"
MOUNT_POINT="/mnt/storage"

#==============================================================================
# USER CONFIGURATION
#==============================================================================

# List of users to create (space-separated)
# Example: "alice bob charlie dave eve"
# Example: "user1 user2 user3"
USERS="alice bob charlie dave eve"

# Starting UID for users (default: 1000)
FIRST_UID=1000

USER_SHELL="/bin/bash"
USER_GROUPS="docker sudo"

#==============================================================================
# STORAGE CONFIGURATION
#==============================================================================

# Leave empty for auto-detection, or specify devices
# Auto-detection will find NVMe/SSD and all rotational HDDs

# SSD/NVMe device (auto-detected if empty)
# Example: "/dev/nvme0n1" or "/dev/sda"
NVME_DEVICE=""

# Size to reserve for OS (in GB), rest used for bcache
# Example: 50 (smaller OS partition), 200 (larger system partition)
OS_PARTITION_SIZE_GB=100

# HDD devices for BTRFS (auto-detected if empty)
# Example: "/dev/sdb /dev/sdc /dev/sdd /dev/sde"
HDD_DEVICES=""

# BTRFS RAID level - Choose based on disk count:
# - raid10: 4+ disks (best performance + redundancy, ~50% usable space)
# - raid1:  2+ disks (mirroring, ~50% usable space)
# - raid0:  2+ disks (fast but NO redundancy, ~100% usable space)
# - single: 1+ disk  (no redundancy, 100% usable space)
BTRFS_RAID_LEVEL="raid10"

# Compression: zstd:1-15 (higher=better compression, more CPU), lzo, zlib, none
# - zstd:1  = light compression (less CPU, less space savings)
# - zstd:3  = balanced (default)
# - zstd:15 = maximum compression (more CPU, more space savings)
BTRFS_COMPRESSION="zstd:3"

# bcache mode:
# - writeback:    Best performance, requires UPS
# - writethrough: Safer, slightly slower
# - writearound:  Write-around (rarely used)
# - none:         Disable bcache (if no SSD/NVMe)
BCACHE_MODE="writeback"

#==============================================================================
# RESOURCE LIMITS (PER USER)
#==============================================================================

MEMORY_GUARANTEE_GB=32
MEMORY_LIMIT_GB=100
SWAP_SIZE_GB=50

#==============================================================================
# DOCKER CONFIGURATION
#==============================================================================

DOCKER_STORAGE_DRIVER="btrfs"
DOCKER_LOG_MAX_SIZE="10m"
DOCKER_LOG_MAX_FILES="3"

#==============================================================================
# NETWORKING
#==============================================================================

# Your domain for Cloudflare Tunnel
# Example: "example.com" creates alice-code.example.com, alice-jupyter.example.com, etc.
DOMAIN=""

CODE_SERVER_PREFIX="code"
JUPYTER_PREFIX="jupyter"

# Local network CIDR for firewall (optional)
# Example: "192.168.1.0/24"
LOCAL_NETWORK_CIDR=""

#==============================================================================
# BACKUP CONFIGURATION
#==============================================================================

BACKUP_REMOTE="gdrive:backups/ml-train-server"
BACKUP_BANDWIDTH_LIMIT_MBPS=100

SNAPSHOT_HOURLY_KEEP=24
SNAPSHOT_DAILY_KEEP=7
SNAPSHOT_WEEKLY_KEEP=4

RESTIC_KEEP_DAILY=7
RESTIC_KEEP_WEEKLY=52

BACKUP_HOUR=6
BACKUP_MINUTE=0

#==============================================================================
# DATA PIPELINE
#==============================================================================

GCS_BUCKET="gcs:customer-daily-bucket"
GDRIVE_CUSTOMER_DATA="gdrive:customer-daily"
DATA_SYNC_BANDWIDTH_LIMIT_MBPS=100
DATA_SYNC_HOUR=4
DATA_SYNC_MINUTE=0
DATA_CLEANUP_DAYS=90

#==============================================================================
# STORAGE ALLOCATION LIMITS (per user)
#==============================================================================

# Per-user total storage quota (in GB)
# Covers combined usage across home directory, workspace, and docker volumes
# Breakdown example (not enforced separately):
#   - Home directory (~100GB): Code, configs, dotfiles, papers, venvs (backed up)
#   - Workspace (~800GB): Training data, model checkpoints, datasets (NOT backed up)
#   - Docker volumes (~100GB): Container persistent state (backed up)
# Total: 1TB per user
USER_QUOTA_GB=1000

# Quota warning threshold (percentage)
# Alert when user exceeds this percentage of their quota
USER_QUOTA_WARNING_PERCENT=80  # Warn at 80% usage (800GB for 1000GB quota)

# Snapshot overhead multiplier
# BTRFS snapshots use copy-on-write, storing only changed blocks
# With retention policy of 24 hourly + 7 daily + 4 weekly snapshots,
# snapshots typically hold 30-50% of changed data over time
# Formula: snapshot_overhead = total_user_data Ã— SNAPSHOT_OVERHEAD_MULTIPLIER
SNAPSHOT_OVERHEAD_MULTIPLIER=0.5  # 50% of user data

# Storage safety margin (percentage)
# This percentage of free space (after user data + snapshots) is kept as buffer
# Prevents BTRFS performance degradation (performs poorly when >90% full)
# Also allows for unexpected growth and ensures VFS cache has eviction headroom
STORAGE_SAFETY_MARGIN_PERCENT=20  # Keep 20% free, VFS cache uses remaining 80%

# Estimated total storage capacity (in GB)
# Used for validation checks before storage setup
# Examples: 20000 (20TB for 2x20TB RAID1), 40000 (40TB for 4x20TB RAID10)
ESTIMATED_CAPACITY_GB=40000

#==============================================================================
# GOOGLE DRIVE SHARED DRIVE (for /shared mount)
#==============================================================================

# Remote name for Google Workspace Shared Drive
# This will be created during setup with: rclone config
GDRIVE_SHARED_REMOTE="gdrive-shared"

# Local cache directory for Google Drive files
# Large cache provides near-local performance
GDRIVE_CACHE_DIR="${MOUNT_POINT}/cache/gdrive"

# Maximum age for cached files (examples: "24h", "72h", "168h"/1week, "720h"/30days)
# Files not accessed for this duration will be evicted from cache
GDRIVE_CACHE_MAX_AGE="720h"

# rclone VFS cache mode (recommended: full)
# - full: Download entire file on first access, keep in cache
# - writes: Cache writes only
# - minimal: Minimal caching
GDRIVE_VFS_CACHE_MODE="full"

# Write-back cache duration (how long to buffer writes before uploading)
# Examples: "5s", "30s", "1m", "5m"
GDRIVE_WRITE_BACK="5s"

# Read chunk sizes (tune for performance)
# Larger chunks = fewer API calls but more memory
GDRIVE_READ_CHUNK_SIZE="128M"
GDRIVE_READ_CHUNK_LIMIT="off"  # Disable limit for best performance

# Buffer size for reading files
GDRIVE_BUFFER_SIZE="128M"

# Directory cache time (how long to cache directory listings)
GDRIVE_DIR_CACHE_TIME="5m"

# Poll interval for detecting remote changes
# Lower = more API calls but faster change detection
GDRIVE_POLL_INTERVAL="1m"

# Upload chunk size (must be multiple of 256K)
GDRIVE_CHUNK_SIZE="256M"

# Files smaller than this are uploaded in one request
GDRIVE_UPLOAD_CUTOFF="256M"

# Number of parallel transfers and checkers
GDRIVE_TRANSFERS=8
GDRIVE_CHECKERS=16

# Logging
GDRIVE_LOG_LEVEL="INFO"  # DEBUG, INFO, NOTICE, ERROR

#==============================================================================
# MONITORING & ALERTING
#==============================================================================

# Telegram Bot Configuration (leave empty to skip)
# How to set up:
# 1. Open Telegram and search for @BotFather
# 2. Send /newbot and follow the prompts to create your bot
# 3. Copy the bot token (looks like: 123456789:ABCdefGHIjklMNOpqrsTUVwxyz)
# 4. Start a chat with your new bot (send any message)
# 5. Message @userinfobot or @RawDataBot to get your chat ID
# 6. Add both values below
TELEGRAM_BOT_TOKEN=""
TELEGRAM_CHAT_ID=""

# healthchecks.io URLs (leave empty to skip)
HEALTHCHECK_BACKUP_URL=""
HEALTHCHECK_DATA_SYNC_URL=""

GPU_TEMP_THRESHOLD=80
DISK_TEMP_THRESHOLD=50
FS_USAGE_THRESHOLD=90
SMART_MONITORING=true

#==============================================================================
# SERVICE PORTS
#==============================================================================
# Note: VS Code and Jupyter are accessed via Traefik hostnames, not direct ports
# They run on container ports 8080 (code-server) and 8888 (jupyter) internally
# Access via: https://{username}-code.{domain} and https://{username}-jupyter.{domain}

TRAEFIK_PORT=8080
NETDATA_PORT=19999
PROMETHEUS_PORT=9090
GRAFANA_PORT=3000
PORTAINER_PORT=9000
FILEBROWSER_PORT=8081
DOZZLE_PORT=8082
TENSORBOARD_PORT=6006
# NoMachine ports: 4000+ (NX protocol)
# Ports are assigned per user: alice=4000, bob=4001, etc.

#==============================================================================
# ADVANCED SETTINGS
#==============================================================================

ENABLE_AUDITD=false
ENABLE_UPS_MONITORING=false
ENABLE_GPU_TIMESLICING=false
ENABLE_AUTO_UPDATES=true

COMPOSE_PROJECT_NAME="ml-train-server"

#==============================================================================
# HELPER FUNCTIONS (DO NOT EDIT)
#==============================================================================

get_users() { echo ${USERS}; }
get_user_count() { echo ${USERS} | wc -w; }

get_user_uid() {
    local username=$1
    local index=0
    for user in ${USERS}; do
        [[ "$user" == "$username" ]] && echo $((FIRST_UID + index)) && return
        ((index++))
    done
}

get_user_port() {
    local username=$1
    local base_port=$2
    local index=0
    for user in ${USERS}; do
        [[ "$user" == "$username" ]] && echo $((base_port + index)) && return
        ((index++))
    done
}

detect_nvme_device() {
    [[ -n "${NVME_DEVICE}" ]] && echo "${NVME_DEVICE}" && return
    [[ -b "/dev/nvme0n1" ]] && echo "/dev/nvme0n1" && return
    [[ -b "/dev/sda" ]] && echo "/dev/sda" && return
}

detect_hdd_devices() {
    [[ -n "${HDD_DEVICES}" ]] && echo "${HDD_DEVICES}" && return
    local nvme_dev=$(detect_nvme_device)
    local hdds=""
    for dev in /dev/sd{b..z}; do
        if [[ -b "${dev}" ]] && [[ "${dev}" != "${nvme_dev}" ]]; then
            local disk_name=$(basename ${dev})
            if [[ -f "/sys/block/${disk_name}/queue/rotational" ]]; then
                [[ "$(cat /sys/block/${disk_name}/queue/rotational)" == "1" ]] && hdds="${hdds} ${dev}"
            fi
        fi
    done
    echo ${hdds}
}

get_rclone_bandwidth() { echo "${1}M"; }

# Export all
export SERVER_HOSTNAME MOUNT_POINT USERS FIRST_UID USER_SHELL USER_GROUPS
export NVME_DEVICE HDD_DEVICES OS_PARTITION_SIZE_GB
export BTRFS_RAID_LEVEL BTRFS_COMPRESSION BCACHE_MODE
export MEMORY_GUARANTEE_GB MEMORY_LIMIT_GB SWAP_SIZE_GB
export DOCKER_STORAGE_DRIVER DOCKER_LOG_MAX_SIZE DOCKER_LOG_MAX_FILES
export DOMAIN CODE_SERVER_PREFIX JUPYTER_PREFIX LOCAL_NETWORK_CIDR
export BACKUP_REMOTE BACKUP_BANDWIDTH_LIMIT_MBPS
export SNAPSHOT_HOURLY_KEEP SNAPSHOT_DAILY_KEEP SNAPSHOT_WEEKLY_KEEP
export RESTIC_KEEP_DAILY RESTIC_KEEP_WEEKLY BACKUP_HOUR BACKUP_MINUTE
export GCS_BUCKET GDRIVE_CUSTOMER_DATA DATA_SYNC_BANDWIDTH_LIMIT_MBPS
export DATA_SYNC_HOUR DATA_SYNC_MINUTE DATA_CLEANUP_DAYS
export USER_QUOTA_GB USER_QUOTA_WARNING_PERCENT
export SNAPSHOT_OVERHEAD_MULTIPLIER STORAGE_SAFETY_MARGIN_PERCENT ESTIMATED_CAPACITY_GB
export GDRIVE_SHARED_REMOTE GDRIVE_CACHE_DIR GDRIVE_CACHE_MAX_AGE
export GDRIVE_VFS_CACHE_MODE GDRIVE_WRITE_BACK GDRIVE_READ_CHUNK_SIZE GDRIVE_READ_CHUNK_LIMIT
export GDRIVE_BUFFER_SIZE GDRIVE_DIR_CACHE_TIME GDRIVE_POLL_INTERVAL
export GDRIVE_CHUNK_SIZE GDRIVE_UPLOAD_CUTOFF GDRIVE_TRANSFERS GDRIVE_CHECKERS GDRIVE_LOG_LEVEL
export TELEGRAM_BOT_TOKEN TELEGRAM_CHAT_ID HEALTHCHECK_BACKUP_URL HEALTHCHECK_DATA_SYNC_URL
export GPU_TEMP_THRESHOLD DISK_TEMP_THRESHOLD FS_USAGE_THRESHOLD SMART_MONITORING
export ENABLE_AUDITD ENABLE_UPS_MONITORING ENABLE_GPU_TIMESLICING ENABLE_AUTO_UPDATES
export COMPOSE_PROJECT_NAME
